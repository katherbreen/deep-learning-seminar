{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT PACKAGES\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# data analysis packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# misc. packages\n",
    "from random import shuffle  # shuffle elements in a list\n",
    "import pickle  # pythonic file compression\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in and preprocess data\n",
    "\n",
    "X = pd.read_csv('pulse2d_iterinput.txt', sep='\\t')  # read in static simulation inputs (Dx, Dy, C0, etc...)\n",
    "out_dict = pickle.load(open(\"pulse2d_iteroutput.pkl\", \"rb\"))  # read in simulation outputs\n",
    "data = out_dict[0]  # read in the first output to get the shape\n",
    "Nsamples = 1000  # number of samples for all I/O is equal to the number of simulations\n",
    "Ndomain_nodes = data.shape[0]  # number of 'timesteps', in this case is equal to the number of domain nodes\n",
    "XNfeatures = X.shape[1]  # static features\n",
    "YNfeatures = Ndomain_nodes  # only one prediction of interest....(Cmax)\n",
    "Ydim = (X.shape[0], YNfeatures)  # dimension for 2d output\n",
    "Y = np.zeros(Ydim)  # initialize 2d dynamic output...\n",
    "\n",
    "# build X and Y - read in dynamic I/O...i.e. output from the pulse2d model.\n",
    "\n",
    "start_idx = 0\n",
    "for i in out_dict:\n",
    "    data = out_dict[i]\n",
    "    Y[i,:] = data.Cmax.values\n",
    "\n",
    "# normalize 2d inputs across features\n",
    "X = preprocessing.normalize(X,norm='l2', axis=0)\n",
    "    \n",
    "# scale output datasets...this isn't strictly necessary but makes the output more interpretable when prediction values are scales between zero and 1\n",
    "Y = Y/100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and partition data into train/test sets\n",
    "\n",
    "# static data\n",
    "ismpls = list(i for i in range(0,X.shape[0]))  # create list of integers 1:Nsamples (row indices for all I/O)\n",
    "shuffle(ismpls)  # randomize sample/row indices \n",
    "ismpls = np.argsort(ismpls) \n",
    "# reorder each dataset using the randomized row indices set above. then, partition each dataset into train/test sets\n",
    "X = X[ismpls,:]\n",
    "split_idx = int(np.round(X.shape[0] * 0.9))\n",
    "X_train = X[:split_idx,:]\n",
    "X_test = X[split_idx:,:]\n",
    "\n",
    "# 2d data\n",
    "ismpls = list(i for i in range(0,X.shape[0])) \n",
    "shuffle(ismpls)  \n",
    "ismpls = np.argsort(ismpls)\n",
    "staticd = X[ismpls,:]\n",
    "Y = Y[ismpls,:]\n",
    "split_idx = int(np.round(X.shape[0] * 0.9))\n",
    "X_train = X[:split_idx,:]\n",
    "X_test = X[split_idx:,:]\n",
    "Y_train = Y[:split_idx,:]\n",
    "Y_test = Y[split_idx:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write preprocessed data to *.hdf5 file\n",
    "\n",
    "with h5py.File('pulse2D_MLP_X.hdf5','w') as f:\n",
    "    x_train = f.create_dataset('X_train', shape=X_train.shape, data=X_train)\n",
    "    x_test = f.create_dataset('X_test', shape=X_test.shape, data=X_test)\n",
    "\n",
    "with h5py.File('pulse2D_MLP_Y.hdf5','w') as f:\n",
    "    y_train = f.create_dataset('Y_train', shape=Y_train.shape, data=Y_train)\n",
    "    y_test = f.create_dataset('Y_test', shape=Y_test.shape, data=Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
