{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#%% IMPORT PACKAGES\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "#from matplotlib import rcParams  # next 3 lines set font family for plotting\n",
    "#rcParams['font.family'] = 'serif'\n",
    "#rcParams['font.sans-serif'] = ['TImes New Roman']\n",
    "#import matplotlib.pyplot as plt\n",
    "#\n",
    "#from keras.utils import plot_model\n",
    "#os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/release/bin'\n",
    "\n",
    "# set working directory (change the following path to match your directory structure)\n",
    "main = 'C:\\\\Users\\\\Kathy_Breen\\\\Documents\\\\DL_Seminar\\\\Week3'  # set directory path where this file is saved\n",
    "os.chdir(main)  # make sure the Spyder is pointing to the correct folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% SETTINGS FOR REPRODUCIBLE RESULTS DURING DEVELOPMENT\n",
    "\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "# The below is necessary in Python 3.2.3 onwards to\n",
    "# have reproducible behavior for certain hash-based operations.\n",
    "# See these references for further details:\n",
    "# https://docs.python.org/3.4/using/cmdline.html#envvar-PYTHONHASHSEED\n",
    "# https://github.com/keras-team/keras/issues/2280#issuecomment-306959926\n",
    "\n",
    "#import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "\n",
    "rn.seed(12345)\n",
    "\n",
    "# Force TensorFlow to use single thread.\n",
    "# Multiple threads are a potential source of\n",
    "# non-reproducible results.\n",
    "# For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "# The below tf.set_random_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "tf.set_random_seed(1234)  \n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% Read in *.hdf5 data sets\n",
    "\n",
    "with h5py.File('X.hdf5','r') as f:\n",
    "    X_train = np.array(f[\"X_train\"])\n",
    "    X_test = np.array(f[\"X_test\"])\n",
    "\n",
    "with h5py.File('Y.hdf5','r') as f:\n",
    "    Y_train = np.array(f[\"Y_train\"])\n",
    "    Y_test = np.array(f[\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% Variables\n",
    "    \n",
    "tic = time.time()  # start a timer\n",
    "\n",
    "# define number of X and Y features\n",
    "X_Nfeatures = X_train.shape[1]\n",
    "Y_Nfeatures = Y_train.shape[1]\n",
    "epochs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% Build MLP model inside a function to call later\n",
    "\n",
    "def run_MLP(X_Nfeatures, Y_Nfeatures, X_train, X_test, Y_train, Y_test, epochs, batch_size, do, Nlyr, Nnodes, run):\n",
    "    # create input layer..........\n",
    "    main_input = Input(shape=(X_Nfeatures),\n",
    "                       dtype='float',\n",
    "                       batch_shape=(batch_size,X_Nfeatures),\n",
    "                       name='main_input'\n",
    "                       )\n",
    "    #create hidden layer..........\n",
    "    hidden_layer = Dense(Nnodes, activation='relu', name='hidden_layer1')(main_input)\n",
    "    # add dropout to hidden layer\n",
    "    Dropout(do)(hidden_layer)\n",
    "    if Nlyr > 1:\n",
    "        for i in range(1,Nlyr):\n",
    "            hidden_layer = Dense(Nnodes, activation='relu', name='hidden_layer'+str(i+1))(hidden_layer)\n",
    "            # add dropout to hidden layer\n",
    "            Dropout(do)(hidden_layer)\n",
    "    \n",
    "    # create output layer\n",
    "    main_output = Dense(Y_Nfeatures, name='main_output')(hidden_layer)  # default activation is linear\n",
    "    \n",
    "    # feed datasets into model for training\n",
    "    model = Model(inputs=[main_input], \n",
    "                  outputs=[main_output]\n",
    "                  )\n",
    "    \n",
    "    # compile the model with desired configuration\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer='adagrad',\n",
    "                  metrics=['mae'])\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='val_loss', # quantity to monitor\n",
    "                               min_delta=0.0001,  # min change to qualify as an improvement\n",
    "                               patience=100, # stop after #epochs with no improvement\n",
    "                               verbose=1)  # print messages\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                  factor=0.2,  # reduction factor (new_lr = lr * factor)\n",
    "                                  patience=15,\n",
    "                                  verbose=1)\n",
    "    \n",
    "    # train the model, and store training information in the history object\n",
    "    history = model.fit([X_train],[Y_train],\n",
    "                        epochs=epochs,\n",
    "                        batch_size = batch_size,\n",
    "                        validation_data=([X_test], [Y_test]),\n",
    "#                        callbacks=[reduce_lr]\n",
    "#                        callbacks=[early_stop]\n",
    "                        callbacks=[reduce_lr,early_stop]\n",
    "                        )\n",
    "    histdict = history.history\n",
    "\n",
    "    predict = model.predict([X_test],batch_size=batch_size)\n",
    "    Y_mse = mean_squared_error(predict,Y_test)\n",
    "    \n",
    "#    main_loss_train = histdict['loss']\n",
    "#    main_loss_test = histdict['val_loss']\n",
    "#    xplot = list(range(len(main_loss_train)))\n",
    "#    \n",
    "#    fig = plt.figure(num=1, figsize=(8,6))\n",
    "#    ax = fig.add_subplot(111)\n",
    "#    train = ax.plot(xplot,main_loss_train,'b-',label='Train',linewidth=4)\n",
    "#    test = ax.plot(xplot,main_loss_test,'r-',label='Test',linewidth=4)\n",
    "#    ax.set_xlabel('Epochs')\n",
    "#    ax.set_ylabel('Loss')\n",
    "#    curves = train+test\n",
    "#    labels = [c.get_label() for c in curves]\n",
    "#    ax.legend(curves, labels, loc=0)\n",
    "#    plt.tight_layout()\n",
    "#    plt.title(str(hparams.loc[run,:]))\n",
    "#    plt.savefig('main_loss_' + str(run) + '.jpg')\n",
    "#    plt.show()\n",
    "#    \n",
    "#    fig = plt.figure(num=2, figsize=(8,6))\n",
    "#    ax = fig.add_subplot(111)\n",
    "#    y_true = ax.plot(X_test,Y_test,'ko',markersize=16,label=r'$Y_{true}$')\n",
    "#    y_pred = ax.plot(X_test,predict,'*',color='#009191',markersize=10,label=r'$\\hat{Y}_{main}$')\n",
    "#    ax.set_xlabel(r'$X$')\n",
    "#    ax.set_ylabel(r'$Y$')\n",
    "#    curves = y_true+y_pred\n",
    "#    labels = [c.get_label() for c in curves]\n",
    "#    ax.legend(curves, labels, loc=0)\n",
    "#    plt.tight_layout()\n",
    "#    plt.title(str(hparams.loc[run,:]))\n",
    "#    plt.savefig('ypred2_' + str(run) + '.jpg')\n",
    "#    plt.show()\n",
    "#    \n",
    "#    plot_model(model, to_file='DLM_basic2_structure_' + str(run) +'.jpg', show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "    return histdict, predict, Y_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% Call the function to perform hyperparaeter tuning\n",
    "    \n",
    "# run model with hyperparameter values and save RMSE and loss to a dictionary\n",
    "rundict = {}\n",
    "\n",
    "tic = time.time()\n",
    "hparams = pd.read_csv('h_tuning.txt',sep='\\t')\n",
    "for row in range(hparams.shape[0]):\n",
    "    batch_size = hparams.loc[row,'batch_size']\n",
    "    do = hparams.loc[row,'do']\n",
    "    Nlyr = hparams.loc[row,'Nlyr']\n",
    "    Nnodes = hparams.loc[row,'Nnodes']\n",
    "    \n",
    "    # MLP\n",
    "    histdict, predict, Y_mse = run_MLP(X_Nfeatures, Y_Nfeatures, X_train, X_test, Y_train, Y_test, epochs, batch_size, do, Nlyr, Nnodes, row)\n",
    "    rundict[row] = {'histdict': histdict, 'predict': predict, 'Y_mse': Y_mse}\n",
    "    \n",
    "toc = (time.time() - tic)/60\n",
    "print('Elapsed time: ' + str(toc) + ' minutes')\n",
    "    \n",
    "pickle.dump(rundict, open( \"HyperParamOut.pkl\", \"wb\" ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
